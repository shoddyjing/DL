{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train label:(60000,)\n",
      "shape of test label:(10000,)\n",
      "train_size:60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.10771666666666667\n"
     ]
    }
   ],
   "source": [
    "#ch03.06 page 70-78\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "sys.path.append(os.pardir) #将父目录（上一级）os.pardir添加到系统搜索路径\n",
    "#print(os.pardir) # 输出‘..’\n",
    "from dataset.mnist import load_mnist #在上一级中搜索dataset文件夹（模块）并得到其中mnist.py文件\n",
    "from PIL import Image\n",
    "\n",
    "def img_show(img):\n",
    "    pil_img=Image.fromarray(np.uint8(img))  #unit8, 0~255内存储图像的np数组\n",
    "    pil_img.show()\n",
    "\n",
    "#step function\n",
    "def step_function(x):# if x>=0:  return 1 elif x<0: return 0\n",
    "    #y=np.array(x>0)\n",
    "    y=np.array(x>0, dtype=np.int)         \n",
    "    return y\n",
    "\n",
    "def sigmoid(x):\n",
    "    y=1/(1+np.exp(-x))  #和非数组计算的广播功能\n",
    "    return y\n",
    "\n",
    "#Rectified Linear Unit function\n",
    "def ReLU(x):\n",
    "  #  y=np.array(x)\n",
    "  #  y[y<=0]=0.0\n",
    "  #  return y\n",
    "    return(np.maximum(x,0)) \n",
    "\n",
    "#1. identity_function 恒等函数，apply to regression problems 适合回归问题\n",
    "def identity(a):\n",
    "    return a\n",
    "\n",
    "#2. softmax_function ，apply to classification problems 适合分类问题\n",
    "def softmax(a):\n",
    "    c=np.max(a)\n",
    "    exp_a=np.exp(a-c)    #通过减去最大值防止因e指数后各个数值相差太大而出现的溢出现象。\n",
    "    sum_exp_a=np.sum(exp_a)\n",
    "    y=exp_a/sum_exp_a  #sum_exp_a为一个常数，此处使用了广播功能\n",
    "    return y           #sum(y)=1,且y的大小顺序同输入a(y=e**a为单调递增函数)，所以softmax层有时会被省略\n",
    "    \n",
    "def init_network(input_size,hidden_size1,hidden_size2,output_size): \n",
    "    network={}    #创建字典型变量存储权重和偏置值\n",
    "    network['w1']=np.random.randn(input_size,hidden_size1)*2**0.5/np.sqrt(input_size) #高斯分布+He初始值\n",
    "    network['b1']=np.zeros(hidden_size1)\n",
    "    network['w2']=np.random.randn(hidden_size1,hidden_size2)*2**0.5/np.sqrt(hidden_size1)\n",
    "    network['b2']=np.zeros(hidden_size2)\n",
    "    network['w3']=np.random.randn(hidden_size2,output_size)*2**0.5/np.sqrt(hidden_size2)\n",
    "    network['b3']=np.array(output_size)\n",
    "    return network\n",
    "\n",
    "def forward(network,x):\n",
    "    w1,w2,w3=network['w1'],network['w2'],network['w3']\n",
    "    b1,b2,b3=network['b1'],network['b2'],network['b3']\n",
    "    \n",
    "    a1=np.dot(x,w1)+b1\n",
    "    z1=sigmoid(a1)     #中间层值为a->z，输出层为y\n",
    "    a2=np.dot(z1,w2)+b2\n",
    "    z2=sigmoid(a2)\n",
    "    a3=np.dot(z2,w3)+b3\n",
    "    y=softmax(a3) #softmax适合分类问题\n",
    "    #y=identity(a3)\n",
    "    return y\n",
    "\n",
    "def get_data():\n",
    "    (x_train, t_train), (x_test, t_test)= load_mnist(flatten=True, normalize=False, one_hot_label=False)\n",
    "   # print(\"shape of train data:{}\".format(x_train.shape))\n",
    "    print(\"shape of train label:{}\".format(t_train.shape))\n",
    "   # print(\"shape of test data:{}\".format(x_test.shape))\n",
    "    print(\"shape of test label:{}\".format(t_test.shape))\n",
    "    return x_train, t_train, x_test, t_test\n",
    "    \n",
    "\n",
    "x_train,t_train,x_test,t_test=get_data()\n",
    "\n",
    "'''\n",
    "#打印示例图片\n",
    "img_ex=x_train[0]\n",
    "label_ex=t_train[0]\n",
    "print(\"示例标签：{}\".format(label_ex))\n",
    "print(\"示例图像读入形状：{}\".format(img_ex.shape))\n",
    "img_ex=img_ex.reshape(28,28)\n",
    "print(\"示例图像输出形状filter{}\".format(img_ex.shape))\n",
    "print(\"输出图像：\")\n",
    "img_show(img_ex)\n",
    "'''\n",
    "\n",
    "#训练权重数据，隐藏层1含有50个神经元，隐藏层2含有100个神经元\n",
    "train_size=t_train.shape[0]\n",
    "print(\"train_size:{}\".format(train_size))\n",
    "network=init_network(input_size=784,hidden_size1=100,hidden_size2=100,output_size=10)\n",
    "batch_size=100\n",
    "batch_mask=np.random.choice(train_size,batch_size)\n",
    "x=x_train#[batch_mask]\n",
    "t=t_train#[batch_mask]\n",
    "accuracy_cnt=0\n",
    "\n",
    "for i in range(len(x)):\n",
    "    y=forward(network,x[i])\n",
    "    p=np.argmax(y)\n",
    "    if p==t[i]:\n",
    "        accuracy_cnt+=1\n",
    "#print(\"accuracy:{}\".format(float(accuracy_cnt)/batch_size))\n",
    "print(\"accuracy:{}\".format(float(accuracy_cnt)/len(x)))\n",
    "\n",
    "#print(y)\n",
    "\n",
    "#try:    \n",
    "#    !jupyter nbconvert --to python 3layered_neural_network_forward.ipynb\n",
    "#    # python即转化为.py，script即转化为.html\n",
    "#except:\n",
    "#    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
